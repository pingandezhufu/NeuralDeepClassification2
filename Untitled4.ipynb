{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "9 classes\n",
      "93 dims\n",
      "Building model...\n",
      "Training model...\n",
      "Train on 55071 samples, validate on 6807 samples\n",
      "Epoch 0\n",
      "55071/55071 [==============================] - 102s - loss: 0.9597 - acc.: 0.6823 - val. loss: 0.7333 - val. acc.: 0.7290\n",
      "Epoch 1\n",
      "55071/55071 [==============================] - 116s - loss: 0.7707 - acc.: 0.7264 - val. loss: 0.6844 - val. acc.: 0.7497\n",
      "Epoch 2\n",
      "55071/55071 [==============================] - 124s - loss: 0.7308 - acc.: 0.7360 - val. loss: 0.6631 - val. acc.: 0.7505\n",
      "Epoch 3\n",
      "13472/55071 [======>.......................] - ETA: 98s - loss: 0.7240 - acc.: 0.7364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n",
      "ERROR: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 970, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 233, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 267, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1044, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1004, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 500, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python2.7/posixpath.py\", line 383, in realpath\n",
      "    return abspath(path)\n",
      "  File \"/usr/lib/python2.7/posixpath.py\", line 373, in abspath\n",
      "    return normpath(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 970, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 233, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 285, in _fixed_getinnerframes\n",
      "    lines = ulinecache.getlines(file)[start:end]\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/utils/ulinecache.py\", line 37, in getlines\n",
      "    return [l.decode(encoding, 'replace') for l in lines]\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 3000, in run_ast_nodes\n    self.showtraceback()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 1851, in showtraceback\n    value, tb, tb_offset=tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1240, in structured_traceback\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1148, in structured_traceback\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1000, in structured_traceback\n    tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 951, in format_exception_as_a_whole\n    frames = self.format_records(records)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 724, in format_records\n    for frame, file, lnum, func, lines, index in records:\n",
      "TypeError: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''\n",
    "    This demonstrates how to reach a score of 0.4890 (local validation)\n",
    "    on the Kaggle Otto challenge, with a deep net using Keras.\n",
    "    Compatible Python 2.7-3.4\n",
    "    Recommended to run on GPU:\n",
    "        Command: THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python kaggle_otto_nn.py\n",
    "        On EC2 g2.2xlarge instance: 19s/epoch. 6-7 minutes total training time.\n",
    "    Best validation score at epoch 21: 0.4881\n",
    "    Try it at home:\n",
    "        - with/without BatchNormalization (BatchNormalization helps!)\n",
    "        - with ReLU or with PReLU (PReLU helps!)\n",
    "        - with smaller layers, largers layers\n",
    "        - with more layers, less layers\n",
    "        - with different optimizers (SGD+momentum+decay is probably better than Adam!)\n",
    "'''\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "def load_data(path, train=True):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.values.copy()\n",
    "    if train:\n",
    "        np.random.shuffle(X) # https://youtu.be/uyUXoap67N8\n",
    "        X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
    "        return X, labels\n",
    "    else:\n",
    "        X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
    "        return X, ids\n",
    "\n",
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler\n",
    "\n",
    "def preprocess_labels(y, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "    y = encoder.transform(labels).astype(np.int32)\n",
    "    if categorical:\n",
    "        y = np_utils.to_categorical(y)\n",
    "    return y, encoder\n",
    "\n",
    "def make_submission(y_prob, ids, encoder, fname):\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('id,')\n",
    "        f.write(','.join([str(i) for i in encoder.classes_]))\n",
    "        f.write('\\n')\n",
    "        for i, probs in zip(ids, y_prob):\n",
    "            probas = ','.join([i] + [str(p) for p in probs.tolist()])\n",
    "            f.write(probas)\n",
    "            f.write('\\n')\n",
    "    print(\"Wrote submission to file {}.\".format(fname))\n",
    "\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X, labels = load_data('train.csv', train=True)\n",
    "X, scaler = preprocess_data(X)\n",
    "y, encoder = preprocess_labels(labels)\n",
    "\n",
    "X_test, ids = load_data('test.csv', train=False)\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "nb_classes = y.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "dims = X.shape[1]\n",
    "print(dims, 'dims')\n",
    "\n",
    "print(\"Building model...\")\n",
    "neurons=512\n",
    "model = Sequential()\n",
    "model.add(Dense(dims, neurons, init='glorot_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization((neurons,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(neurons, neurons/2, init='glorot_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization((neurons/2,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(neurons/2, neurons/4, init='glorot_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization((neurons/4,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(neurons/4, neurons/8, init='glorot_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization((neurons/8,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(neurons/8, nb_classes, init='glorot_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X, y, nb_epoch=40, batch_size=16, validation_split=0.11,show_accuracy=True,verbose=1)\n",
    "\n",
    "\n",
    "print(\"Generating submission...\")\n",
    "\n",
    "proba = model.predict_proba(X_test)\n",
    "\n",
    "make_submission(proba, ids, encoder, fname='Submission11.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
