{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "cannot open doall.lua: No such file or directory\nstack traceback:\n\t[C]: in function 'f'\n\t[string \"local f = function() return dofile('doall.lua...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/usr/local/share/lua/5.1/itorch/main.lua:177: in function </usr/local/share/lua/5.1/itorch/main.lua:143>\n\t/usr/local/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/usr/local/share/lua/5.1/itorch/main.lua:344: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/home/ubuntu/.ipython/profile_default/s...\"]:1: in main chunk",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "cannot open doall.lua: No such file or directory\nstack traceback:\n\t[C]: in function 'f'\n\t[string \"local f = function() return dofile('doall.lua...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/usr/local/share/lua/5.1/itorch/main.lua:177: in function </usr/local/share/lua/5.1/itorch/main.lua:143>\n\t/usr/local/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/usr/local/share/lua/5.1/itorch/main.lua:344: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/home/ubuntu/.ipython/profile_default/s...\"]:1: in main chunk"
     ]
    }
   ],
   "source": [
    "dofile('doall.lua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "cannot open ~/NeuralDeepClassification/doall.lua: No such file or directory\nstack traceback:\n\t[C]: in function 'f'\n\t[string \"local f = function() return dofile('~/NeuralD...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/usr/local/share/lua/5.1/itorch/main.lua:177: in function </usr/local/share/lua/5.1/itorch/main.lua:143>\n\t/usr/local/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/usr/local/share/lua/5.1/itorch/main.lua:344: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/home/ubuntu/.ipython/profile_default/s...\"]:1: in main chunk",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "cannot open ~/NeuralDeepClassification/doall.lua: No such file or directory\nstack traceback:\n\t[C]: in function 'f'\n\t[string \"local f = function() return dofile('~/NeuralD...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/usr/local/share/lua/5.1/itorch/main.lua:177: in function </usr/local/share/lua/5.1/itorch/main.lua:143>\n\t/usr/local/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/usr/local/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/usr/local/share/lua/5.1/itorch/main.lua:344: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/home/ubuntu/.ipython/profile_default/s...\"]:1: in main chunk"
     ]
    }
   ],
   "source": [
    "dofile('~/NeuralDeepClassification/doall.lua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : ByteTensor - size: 10000x3x32x32\n",
       "  label : ByteTensor - size: 10000\n",
       "}\n",
       "\n",
       " 10000\n",
       "     3\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "automobile\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000\t\n",
       "{\n",
       "  1 : DoubleTensor - size: 3x32x32\n",
       "  2 : 2\n",
       "}\n",
       "\n",
       " 10000\n",
       "     1\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 1, Mean: 125.83175029297\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 1, Standard Deviation: 63.143400842609\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Mean: 123.26066621094\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Standard Deviation: 62.369209019002\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Mean: 114.03068681641\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Standard Deviation: 66.965808411114\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip')\n",
    "-- os.execute('unzip cifar10torchsmall.zip')\n",
    "require 'itorch'\n",
    "require 'image'\n",
    "require 'nn'\n",
    "\n",
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n",
    "print(trainset)\n",
    "print(#trainset.data)\n",
    "itorch.image(trainset.data[100]) -- display the 100-th image in dataset\n",
    "print(classes[trainset.label[100]])\n",
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(trainset,\n",
    "    {__index = function(t, i)\n",
    "                    return {t.data[i], t.label[i]}\n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size()\n",
    "    return self.data:size(1)\n",
    "end\n",
    "print(trainset:size()) -- just to test\n",
    "print(trainset[33]) -- load sample number 33.\n",
    "--itorch.image(trainset[33][1])\n",
    "redChannel = trainset.data[{ {}, {1}, {}, {}  }] -- this picks {all images, 1st channel, all vertical pixels, all horizontal pixels}\n",
    "print(#redChannel)\n",
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future\n",
    "for i=1,3 do -- over each image channel\n",
    "    mean[i] = trainset.data[{ {}, {i}, {}, {}  }]:mean() -- mean estimation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction\n",
    "\n",
    "    stdv[i] = trainset.data[{ {}, {i}, {}, {}  }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end\n",
    "\n",
    "    net = nn.Sequential()\n",
    "    net:add(nn.SpatialConvolution(3, 6, 2, 2)) -- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "    net:add(nn.ReLU())\n",
    "    net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "    -- net:add(nn.Dropout(0.25))    -- A m\n",
    "    net:add(nn.SpatialConvolution(6, 64, 2, 2)) -- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "    net:add(nn.ReLU())\n",
    "    net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "    -- net:add(nn.Dropout(0.25))    -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "    -- net:add(nn.SpatialConvolution(64, 64, 2, 2))\n",
    "    -- net:add(nn.ReLU())\n",
    "    -- net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "    -- net:add(nn.Dropout(0.25))\n",
    "    net:add(nn.SpatialConvolution(64, 128, 2, 2))\n",
    "    net:add(nn.ReLU())\n",
    "    -- net:add(nn.Dropout(0.25))\n",
    "    net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "\n",
    "    -- net:add(nn.SpatialConvolution(128, 128, 2, 2))\n",
    "    -- net:add(nn.ReLU())\n",
    "    -- net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "\n",
    "    net:add(nn.SpatialConvolution(128, 256, 2, 2))\n",
    "    net:add(nn.ReLU())\n",
    "    -- net:add(nn.Dropout(0.25))\n",
    "    net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "\n",
    "    -- net:add(nn.SpatialConvolution(256, 256, 2, 2))\n",
    "    -- net:add(nn.ReLU())\n",
    "    -- -- net:add(nn.Dropout(0.25))\n",
    "    -- net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "    -- net:add(nn.SpatialConvolution(256, 1024, 2, 2))\n",
    "    -- net:add(nn.ReLU())\n",
    "    --\n",
    "    -- net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "    -- net:add(nn.SpatialConvolution(1024, 1024, 2, 2))\n",
    "    -- net:add(nn.ReLU())\n",
    "    -- -- net:add(nn.Dropout(0.25))\n",
    "    -- net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "    -- net:add(nn.Dropout(0.50))\n",
    "    net:add(nn.View(256))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "    net:add(nn.Linear(256, 256))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "    net:add(nn.Linear(256, 128))\n",
    "    net:add(nn.Linear(128, 10))\n",
    "    -- net:add(nn.Linear(100, 10))                    -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "    net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems\n",
    "-- net = nn.Sequential()\n",
    "--    net:add(nn.SpatialConvolution(3, 64, 5, 5))\n",
    "--    net:add(nn.ReLU())\n",
    "--    net:add(nn.SpatialConvolution(64, 64, 5, 5))\n",
    "--    net:add(nn.ReLU())\n",
    "--    net:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "--    --net:add(nn.BatchNormalization(64))\n",
    "--    net:add(nn.Dropout(0.25))\n",
    "--\n",
    "--    net:add(nn.SpatialConvolution(64, 128, 5, 5))\n",
    "--    net:add(nn.ReLU())\n",
    "--    net:add(nn.SpatialConvolution(128, 128, 5, 5))\n",
    "--    net:add(nn.ReLU())\n",
    "--    net:add(nn.SpatialMaxPooling(2, 2 , 2, 2))\n",
    "--    --net:add(nn.BatchNormalization(128))\n",
    "--    net:add(nn.Dropout(0.25))\n",
    "--\n",
    "--    net:add(nn.SpatialConvolution(128, 256, 5, 5))\n",
    "--    net:add(nn.ReLU())\n",
    "--    net:add(nn.SpatialConvolution(256, 256, 5, 5))\n",
    "--    net:add(nn.ReLU())\n",
    "--    net:add(nn.SpatialConvolution(256, 256, 5, 5))\n",
    "--    net:add(nn.ReLU())\n",
    "--    net:add(nn.SpatialConvolution(256, 256, 5, 5))\n",
    "--    net:add(nn.ReLU())\n",
    "--    net:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "--\n",
    "--    -- Fully Connected Layers\n",
    "--    net:add(nn.SpatialConvolution(256, 1024, 5, 5))\n",
    "--    net:add(nn.ReLU())\n",
    "--    net:add(nn.Dropout(0.5))\n",
    "--    net:add(nn.View(1024*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "--    net:add(nn.Linear(1024*5*5, 512))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "--    net:add(nn.Linear(512, 256))\n",
    "--    net:add(nn.Linear(256, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "--    net:add(nn.LogSoftMax())\n",
    "\n",
    "   -- all initial values in final layer must be a positive number.\n",
    "   -- this trick is awfully important ('-')b\n",
    "  --  final_mlpconv_layer.weight:abs()\n",
    "  --  final_mlpconv_layer.bias:abs()--net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.01\n",
    "trainer.learningRateDecay=0.0024\n",
    "trainer.maxIteration = 25 -- just do 5 epochs of training.\n",
    "trainer:train(trainset)\n",
    "print(classes[testset.label[100]])\n",
    "--itorch.image(testset.data[100])\n",
    "testset.data = testset.data:double()   -- convert from Byte tensor to Double tensor\n",
    "for i=1,3 do -- over each image channel\n",
    "    testset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction\n",
    "    testset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end\n",
    "-- for fun, print the mean and standard-deviation of example-100\n",
    "horse = testset.data[100]\n",
    "print(horse:mean(), horse:std())\n",
    "print(classes[testset.label[100]])\n",
    "--itorch.image(testset.data[100])\n",
    "predicted = net:forward(testset.data[100])\n",
    "-- the output of the network is Log-Probabilities. To convert them to probabilities, you have to take e^x\n",
    "print(predicted:exp())\n",
    "for i=1,predicted:size(1) do\n",
    "    print(classes[i], predicted[i])\n",
    "end\n",
    "correct = 0\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end\n",
    "print(correct, 100*correct/10000 .. ' % ')\n",
    "class_performance = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end\n",
    "for i=1,#classes do\n",
    "    print(classes[i], 100*class_performance[i]/1000 .. ' %')\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20003"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
